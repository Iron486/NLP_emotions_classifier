{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## <font color='Blue'>BRAIN TUMOR CLASSIFIER REACHING MORE THAN 97% ACCURACY ON VALIDATION DATASET\n</font>","metadata":{}},{"cell_type":"markdown","source":"### For further information about the notebook and clear explanation of each step, click the following link https://github.com/Iron486/NLP_emotions_classifier and check the README.md file. \n\n#### Upvote if you find this notebook useful.","metadata":{}},{"cell_type":"markdown","source":"### <font color='violet'>Import libraries</font>","metadata":{"id":"KuMWoh4eXWWf"}},{"cell_type":"code","source":"import nltk\n\nnltk.download('stopwords')\nnltk.download('wordnet')\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras import layers\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nimport statistics\nfrom numpy import array\nfrom numpy import asarray\nfrom numpy import zeros\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom tensorflow import keras\n\n\n!pip install transformers # install a library not present in Colab\n!pip install contractions\n!pip install spacy==2.2.3\n!python -m spacy download en_core_web_sm\n!pip install beautifulsoup4==4.9.1\n!pip install textblob==0.15.3\n!pip install contractions\n!pip install transformers\n\nimport contractions\nimport re\nimport transformers\nfrom transformers import BertTokenizer, TFBertForSequenceClassification","metadata":{"id":"0529e0da","outputId":"66c00fa4-15d3-4e9f-eeae-cbb10b83b280","execution":{"iopub.status.busy":"2022-06-09T18:58:33.921274Z","iopub.execute_input":"2022-06-09T18:58:33.922072Z","iopub.status.idle":"2022-06-09T19:00:12.978252Z","shell.execute_reply.started":"2022-06-09T18:58:33.922032Z","shell.execute_reply":"2022-06-09T19:00:12.977166Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### <font color='violet'>Preprocessing the datasets</font>","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(r'../input/emotions-dataset-for-nlp/train.txt', names=['sentences', 'emotion'], sep=';')\nval = pd.read_csv(r'../input/emotions-dataset-for-nlp/val.txt', names=['sentences', 'emotion'], sep=';')\ntest = pd.read_csv(r'../input/emotions-dataset-for-nlp/test.txt', names=['sentences', 'emotion'], sep=';')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:00:12.980302Z","iopub.execute_input":"2022-06-09T19:00:12.980651Z","iopub.status.idle":"2022-06-09T19:00:13.075964Z","shell.execute_reply.started":"2022-06-09T19:00:12.980619Z","shell.execute_reply":"2022-06-09T19:00:13.075192Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def Lemmatizer_stop_word(sentence):\n    stop_words = set(stopwords.words('english'))\n    lemmatizer = WordNetLemmatizer() #look at other Lemmatizers and stemmers\n    sentence = re.sub('[^A-z]', ' ', sentence)\n    negative = ['not', 'neither', 'nor', 'but', 'however',\n                'although', 'nonetheless', 'despite', 'except',\n                        'even though', 'yet','unless']\n    stop_words = [z for z in stop_words if z not in negative]\n    preprocessed_tokens = [lemmatizer.lemmatize(contractions.fix(temp.lower())) for temp in sentence.split() if temp not in stop_words] #lemmatization\n    return ' '.join([x for x in preprocessed_tokens]).strip()","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:00:13.077210Z","iopub.execute_input":"2022-06-09T19:00:13.077634Z","iopub.status.idle":"2022-06-09T19:00:13.084812Z","shell.execute_reply.started":"2022-06-09T19:00:13.077596Z","shell.execute_reply":"2022-06-09T19:00:13.083844Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"nltk.download('omw-1.4')\ntrain['sentences'] = train['sentences'].apply(lambda x: Lemmatizer_stop_word(x))\nval['sentences'] = val['sentences'].apply(lambda x: Lemmatizer_stop_word(x))\ntest['sentences'] = test['sentences'].apply(lambda x: Lemmatizer_stop_word(x))\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:00:13.087447Z","iopub.execute_input":"2022-06-09T19:00:13.088246Z","iopub.status.idle":"2022-06-09T19:00:23.865187Z","shell.execute_reply.started":"2022-06-09T19:00:13.088202Z","shell.execute_reply":"2022-06-09T19:00:23.863827Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### <font color='violet'>Tokenize the datasets</font>","metadata":{"id":"O2S6U03yX5eN"}},{"cell_type":"code","source":"max_length=43\nfrom transformers import AutoTokenizer, TFBertModel\ntokenizer=AutoTokenizer.from_pretrained('bert-base-cased')\nbert=TFBertModel.from_pretrained('bert-base-cased')\nfrom tensorflow.keras.layers import Input, Dense\nx_train = tokenizer(\n    [x.split() for x in train['sentences']],\n    add_special_tokens=True,\n    max_length=max_length,\n    truncation=True,\n    padding=True, \n    return_tensors='tf',\n    return_token_type_ids = False,\n    return_attention_mask = True,\n    is_split_into_words=True,\n    verbose = True)\n\n\nx_val = tokenizer(\n    [x.split() for x in val['sentences']],\n    add_special_tokens=True,\n    max_length=max_length,\n    truncation=True,\n    padding=True, \n    return_tensors='tf',\n    return_token_type_ids = False,\n    return_attention_mask = True,\n    is_split_into_words=True,\n    verbose = True)","metadata":{"id":"PJFUKQrpfs0J","execution":{"iopub.status.busy":"2022-06-09T19:00:23.875031Z","iopub.execute_input":"2022-06-09T19:00:23.875992Z","iopub.status.idle":"2022-06-09T19:00:52.969138Z","shell.execute_reply.started":"2022-06-09T19:00:23.875953Z","shell.execute_reply":"2022-06-09T19:00:52.968197Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"lb = LabelEncoder()\nlabels_train=lb.fit(train.loc[:,'emotion'].to_list())\nlabels_train=lb.transform(train.loc[:,'emotion'].to_list())\nlabels_val=lb.transform(val.loc[:,'emotion'].to_list())\nlabels_test=lb.transform(test.loc[:,'emotion'].to_list())","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:00:52.970453Z","iopub.execute_input":"2022-06-09T19:00:52.970858Z","iopub.status.idle":"2022-06-09T19:00:53.007863Z","shell.execute_reply.started":"2022-06-09T19:00:52.970818Z","shell.execute_reply":"2022-06-09T19:00:53.006967Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### <font color='violet'>Train the model</font>","metadata":{"id":"qheaw4F0XEM3"}},{"cell_type":"code","source":"tf.random.set_seed(79)\n#max_len = 43\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.initializers import TruncatedNormal\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.metrics import CategoricalAccuracy\nfrom tensorflow.keras.utils import to_categorical\n\n\ninput_ids = Input(shape=(max_length,), dtype=tf.int32, name=\"input_ids\")\ninput_mask = Input(shape=(max_length,), dtype=tf.int32, name=\"attention_mask\")\n# embeddings = dbert_model(input_ids,attention_mask = input_mask)[0]\n\n\nembeddings = bert(input_ids,attention_mask = input_mask)[0] #(0 is the last hidden states,1 is the pooler_output)\nx = tf.keras.layers.GlobalMaxPool1D()(embeddings)\nx = Dense(138, activation='elu',kernel_initializer='GlorotNormal')(x)\nx = tf.keras.layers.Dropout(0.1)(x)\nx = Dense(28,activation = 'elu',kernel_initializer='GlorotNormal')(x)\n\noutput = Dense(6,activation = 'softmax')(x)\n    \nmodel = tf.keras.Model(inputs=[input_ids, input_mask], outputs=output)\nmodel.layers[2].trainable = True\n\n\nopt = Adam(\n    learning_rate=5e-05, # works well with BERTs\n    epsilon=1e-08,\n    decay=0.01,\n    clipnorm=1.0)\n\nmodel.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy']) \n\n#'sparse_categorical_crossentropy' for not one-hot encoded features\n# summarize the model\nprint(model.summary())\n\n# fit the model\nearly_stopping_cb=keras.callbacks.EarlyStopping(patience=2,restore_best_weights=True)\n#bert_model.trainable = False\n\nhistory = model.fit(\n    x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']} ,\n    y =labels_train,\n    validation_data = (\n    {'input_ids':x_val['input_ids'],'attention_mask':x_val['attention_mask']}, labels_val\n    ),\n  epochs=3,\n    batch_size=12,callbacks=[early_stopping_cb]\n)\n","metadata":{"id":"8e3cdc07","outputId":"6497e6c1-ade0-48db-d741-9dc7607d9c3f","execution":{"iopub.status.busy":"2022-06-09T19:00:53.009442Z","iopub.execute_input":"2022-06-09T19:00:53.010057Z","iopub.status.idle":"2022-06-09T19:09:41.074290Z","shell.execute_reply.started":"2022-06-09T19:00:53.010009Z","shell.execute_reply":"2022-06-09T19:09:41.073349Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### <font color='violet'> History plot </font>","metadata":{"id":"iuMr1qvjYGwl"}},{"cell_type":"code","source":"model.save_weights('Bert_stepword_lemmatizer.h5')\npd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\n#plt.gca().set_xlim(0,33)\nplt.gca().set_ylim(0,1)\nloss, accuracy = model.evaluate({'input_ids':x_val['input_ids'],'attention_mask':x_val['attention_mask']}, labels_val\n    )\nprint('Accuracy: %f' % (accuracy*100))","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:09:41.075979Z","iopub.execute_input":"2022-06-09T19:09:41.077188Z","iopub.status.idle":"2022-06-09T19:09:46.671253Z","shell.execute_reply.started":"2022-06-09T19:09:41.077124Z","shell.execute_reply":"2022-06-09T19:09:46.670457Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### <font color='violet'>Load the weights</font>","metadata":{}},{"cell_type":"code","source":"#rebuild the model to load the weights\n\ninput_ids = Input(shape=(max_length,), dtype=tf.int32, name=\"input_ids\")\ninput_mask = Input(shape=(max_length,), dtype=tf.int32, name=\"attention_mask\")\n\n\nembeddings = bert(input_ids,attention_mask = input_mask)[0] #(0 is the last hidden states,1 is the pooler_output)\nx = tf.keras.layers.GlobalMaxPool1D()(embeddings)\nx = Dense(138, activation='elu',kernel_initializer='GlorotNormal')(x)\nx = tf.keras.layers.Dropout(0.1)(x)\nx = Dense(28,activation = 'elu',kernel_initializer='GlorotNormal')(x)\n\noutput = Dense(6,activation = 'softmax')(x)\n    \nmodel_saved = tf.keras.Model(inputs=[input_ids, input_mask], outputs=output)\nmodel_saved.layers[2].trainable = True\n\n\nmodel_saved.load_weights('Bert_stepword_lemmatizer.h5')","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:09:46.674316Z","iopub.execute_input":"2022-06-09T19:09:46.674639Z","iopub.status.idle":"2022-06-09T19:09:48.528921Z","shell.execute_reply.started":"2022-06-09T19:09:46.674613Z","shell.execute_reply":"2022-06-09T19:09:48.528023Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### <font color='violet'>More details about the model</font>","metadata":{"id":"wx9sRqqxYKtN"}},{"cell_type":"code","source":"model_saved.summary()\n\n#to visualize activation functions\nfor i, layer in enumerate (model.layers):\n    print (i, layer)\n    try:\n        print (\"    \",layer.activation)\n    except AttributeError:\n        print('   no activation attribute')\n#specific info about each layer\nfor i in range(len(model.layers)):\n    print(f'{i}   {model.layers[i]}: \\n{model.layers[i].get_config()} \\n')\n#info about optimizers\nmodel.optimizer.get_config()        ","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:09:48.530112Z","iopub.execute_input":"2022-06-09T19:09:48.530501Z","iopub.status.idle":"2022-06-09T19:09:48.561407Z","shell.execute_reply.started":"2022-06-09T19:09:48.530465Z","shell.execute_reply":"2022-06-09T19:09:48.560486Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### <font color='violet'>Tokenize the test dataset</font>","metadata":{}},{"cell_type":"code","source":"x_test = tokenizer(\n    [x.split() for x in test['sentences']],\n    add_special_tokens=True,\n    max_length=max_length,\n    truncation=True,\n    padding=True, \n    return_tensors='tf',\n    return_token_type_ids = False,\n    return_attention_mask = True,\n    is_split_into_words=True,\n    verbose = True)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:09:48.563001Z","iopub.execute_input":"2022-06-09T19:09:48.563633Z","iopub.status.idle":"2022-06-09T19:09:48.733372Z","shell.execute_reply.started":"2022-06-09T19:09:48.563594Z","shell.execute_reply":"2022-06-09T19:09:48.732431Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### <font color='violet'>Predict on test dataset</font>","metadata":{}},{"cell_type":"code","source":"loss, accuracy = model.evaluate({'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']}, labels_test\n    )\nprint('Accuracy: %f' % (accuracy*100))","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:09:48.734932Z","iopub.execute_input":"2022-06-09T19:09:48.735314Z","iopub.status.idle":"2022-06-09T19:09:53.892489Z","shell.execute_reply.started":"2022-06-09T19:09:48.735276Z","shell.execute_reply":"2022-06-09T19:09:53.891636Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"tf.config.experimental.list_physical_devices('GPU')","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:09:53.893815Z","iopub.execute_input":"2022-06-09T19:09:53.894284Z","iopub.status.idle":"2022-06-09T19:09:53.900663Z","shell.execute_reply.started":"2022-06-09T19:09:53.894244Z","shell.execute_reply":"2022-06-09T19:09:53.899802Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#class-label conversion\nfin_labels=[i.replace(\"\\n\", \"\") for i in train.loc[:,'emotion'].to_list()]\ndict(zip(labels_train,fin_labels))","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:09:53.902377Z","iopub.execute_input":"2022-06-09T19:09:53.902987Z","iopub.status.idle":"2022-06-09T19:09:53.920708Z","shell.execute_reply.started":"2022-06-09T19:09:53.902948Z","shell.execute_reply":"2022-06-09T19:09:53.919779Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### <font color='violet'>Predict a new sentence</font>","metadata":{}},{"cell_type":"code","source":"y=input()","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:09:53.922045Z","iopub.execute_input":"2022-06-09T19:09:53.922430Z","iopub.status.idle":"2022-06-09T19:30:21.965237Z","shell.execute_reply.started":"2022-06-09T19:09:53.922396Z","shell.execute_reply":"2022-06-09T19:30:21.964386Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"y_s=pd.Series([y])\ny_lemm=y_s.apply(lambda x: Lemmatizer_stop_word(x))\ny_tok = tokenizer(\n    [x.split() for x in y_lemm],\n    add_special_tokens=True,\n    max_length=max_length,\n    truncation=True,\n    padding='max_length',  #only for sentence prediction \n    return_tensors='tf',\n    return_token_type_ids = False,\n    return_attention_mask = True,\n    is_split_into_words=True,\n    verbose = True)\n#labels_y=lb.transform(test.loc[:,'emotion'].to_list())\ny_prob=model.predict({'input_ids':y_tok['input_ids'],'attention_mask':y_tok['attention_mask']})*100\n#y_tok\nclass_label=y_prob.argmax(axis=-1)\nlb.inverse_transform(class_label) #from class to label","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:30:21.966310Z","iopub.execute_input":"2022-06-09T19:30:21.966622Z","iopub.status.idle":"2022-06-09T19:30:24.793978Z","shell.execute_reply.started":"2022-06-09T19:30:21.966598Z","shell.execute_reply":"2022-06-09T19:30:24.793114Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"{'input_ids':y_tok['input_ids'],'attention_mask':y_tok['attention_mask']} #bert input parameters","metadata":{"execution":{"iopub.status.busy":"2022-06-09T19:30:24.795113Z","iopub.execute_input":"2022-06-09T19:30:24.795498Z","iopub.status.idle":"2022-06-09T19:30:24.802815Z","shell.execute_reply.started":"2022-06-09T19:30:24.795469Z","shell.execute_reply":"2022-06-09T19:30:24.802013Z"},"trusted":true},"execution_count":19,"outputs":[]}]}